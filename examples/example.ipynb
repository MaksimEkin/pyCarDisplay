{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyCarDisplay.pyCarDisplay import CarDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Car configurations:\n",
      "car_images_path = ../data/2011_09_26/2011_09_26_drive_0002_sync/image_02/data/\n",
      "imu_sensor_path = ../data/2011_09_26/2011_09_26_drive_0002_sync/oxts/data/\n",
      "lidar_sensor_path = ../data/2011_09_26/2011_09_26_drive_0002_sync/velodyne_points/dat/a\n",
      "object_detection_model_path = ../data/checkpoint_ssd300.pth.tar\n",
      "depth_detection_model_path = heh\n",
      "img_resize_size = (300, 300)\n",
      "norm_mean = [0.485, 0.456, 0.406]\n",
      "norm_std = [0.229, 0.224, 0.225]\n",
      "R_covariance = 0.1\n",
      "add_noise = True\n",
      "IMU_names = None\n",
      "gui_speed = 1\n",
      "random_state = 42\n",
      "image_extension = png\n",
      "verbose = True\n",
      "Object detection is using: cpu\n",
      "Object detection API is loading the model: ../data/checkpoint_ssd300.pth.tar\n",
      "\n",
      "Loaded checkpoint from epoch 232.\n",
      "\n",
      "Loading the IMU data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/pycardisplay/lib/python3.8/site-packages/torch/serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.modules.conv.Conv2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/opt/anaconda3/envs/pycardisplay/lib/python3.8/site-packages/torch/serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.modules.pooling.MaxPool2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 77 entries, 0 to 0\n",
      "Data columns (total 31 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   lat           77 non-null     float64\n",
      " 1   lon           77 non-null     float64\n",
      " 2   alt           77 non-null     float64\n",
      " 3   roll          77 non-null     float64\n",
      " 4   pitch         77 non-null     float64\n",
      " 5   yaw           77 non-null     float64\n",
      " 6   vn            77 non-null     float64\n",
      " 7   ve            77 non-null     float64\n",
      " 8   vf            77 non-null     float64\n",
      " 9   vl            77 non-null     float64\n",
      " 10  vu            77 non-null     float64\n",
      " 11  ax            77 non-null     float64\n",
      " 12  ay            77 non-null     float64\n",
      " 13  az            77 non-null     float64\n",
      " 14  af            77 non-null     float64\n",
      " 15  al            77 non-null     float64\n",
      " 16  au            77 non-null     float64\n",
      " 17  wx            77 non-null     float64\n",
      " 18  wy            77 non-null     float64\n",
      " 19  wz            77 non-null     float64\n",
      " 20  wf            77 non-null     float64\n",
      " 21  wl            77 non-null     float64\n",
      " 22  wu            77 non-null     float64\n",
      " 23  pos_accuracy  77 non-null     float64\n",
      " 24  vel_accuracy  77 non-null     float64\n",
      " 25  navstat       77 non-null     int64  \n",
      " 26  numsats       77 non-null     int64  \n",
      " 27  posmode       77 non-null     int64  \n",
      " 28  velmode       77 non-null     int64  \n",
      " 29  orimode       77 non-null     int64  \n",
      " 30  frame         77 non-null     int64  \n",
      "dtypes: float64(25), int64(6)\n",
      "memory usage: 19.2 KB\n",
      "None\n",
      "Initilized IMU\n",
      "Current frame:0\n",
      "Total number of frames:77\n",
      "Total image frames loaded:77\n"
     ]
    }
   ],
   "source": [
    "display = CarDisplay(\n",
    "    car_images_path=\"../data/2011_09_26/2011_09_26_drive_0002_sync/image_02/data/\", \n",
    "    imu_sensor_path='../data/2011_09_26/2011_09_26_drive_0002_sync/oxts/data/',\n",
    "    lidar_sensor_path='../data/2011_09_26/2011_09_26_drive_0002_sync/velodyne_points/dat/a',\n",
    "    object_detection_model_path='../data/checkpoint_ssd300.pth.tar',\n",
    "    depth_detection_model_path='heh',\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame:0\n",
      "<PIL.Image.Image image mode=RGB size=1242x375 at 0x7F8B183DBC10>\n",
      "{'annotated_image': <PIL.Image.Image image mode=RGB size=1242x375 at 0x7F8B183DBC10>, 'box_info': {'text_size': [], 'box_location': []}, 'detected': False}\n",
      "Object detected:0\n",
      "|    |     lat |     lon |     alt |      roll |     pitch |      yaw |       vn |      ve |      vf |         vl |         vu |       ax |        ay |      az |       af |        al |      au |       wx |       wy |        wz |        wf |         wl |         wu |   pos_accuracy |   vel_accuracy |   navstat |   numsats |   posmode |   velmode |   orimode |\n",
      "|---:|--------:|--------:|--------:|----------:|----------:|---------:|---------:|--------:|--------:|-----------:|-----------:|---------:|----------:|--------:|---------:|----------:|--------:|---------:|---------:|----------:|----------:|-----------:|-----------:|---------------:|---------------:|----------:|----------:|----------:|----------:|----------:|\n",
      "|  0 | 48.9542 | 8.61708 | 116.386 | -0.132422 | 0.0962195 | -2.90323 | -3.74651 | -10.149 | 10.5093 | -0.0089432 | -0.0134971 | 0.508146 | -0.144485 | 9.91677 | 0.480288 | 0.0613034 | 9.89323 | 0.106972 | 0.036984 | -0.153594 | 0.0339801 | -0.0352799 | -0.0450832 |      0.0925683 |        0.11872 |   4.09313 |   10.9161 |   5.96908 |   6.03313 |   4.09755 |\n",
      "Frame:1\n",
      "<PIL.Image.Image image mode=RGB size=1242x375 at 0x7F8B084E7EB0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maksimekineren/Desktop/Maksim/UMBC/Classes/Spring 2021/CMSC 611/Project/pyCarDisplay/examples/model.py:504: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  ../aten/src/ATen/native/IndexingUtils.h:30.)\n",
      "  image_boxes.append(class_decoded_locs[1 - suppress])\n",
      "/Users/maksimekineren/Desktop/Maksim/UMBC/Classes/Spring 2021/CMSC 611/Project/pyCarDisplay/examples/model.py:506: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  ../aten/src/ATen/native/IndexingUtils.h:30.)\n",
      "  image_scores.append(class_scores[1 - suppress])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 * 14\n",
      "x = 862.0549926757812\n",
      "y = 150.60012817382812\n",
      "{'annotated_image': <PIL.Image.Image image mode=RGB size=1242x375 at 0x7F8B084E7EB0>, 'box_info': {'text_size': [(64, 14)], 'box_location': [[862.0549926757812, 150.60012817382812, 948.2421875, 300.455078125]]}, 'detected': True}\n",
      "Object detected:1\n",
      "|    |     lat |     lon |     alt |      roll |     pitch |      yaw |       vn |       ve |      vf |         vl |         vu |      ax |         ay |      az |       af |       al |      au |         wx |          wy |        wz |          wf |        wl |       wu |   pos_accuracy |   vel_accuracy |   navstat |   numsats |   posmode |   velmode |   orimode |\n",
      "|---:|--------:|--------:|--------:|----------:|----------:|---------:|---------:|---------:|--------:|-----------:|-----------:|--------:|-----------:|--------:|---------:|---------:|--------:|-----------:|------------:|----------:|------------:|----------:|---------:|---------------:|---------------:|----------:|----------:|----------:|----------:|----------:|\n",
      "|  0 | 48.9665 | 8.41327 | 116.267 | -0.144462 | 0.0938956 | -2.64341 | -3.81077 | -9.91377 | 10.7483 | -0.0808379 | -0.0657743 | 0.67654 | -0.0358738 | 9.62957 | 0.388781 | 0.292543 | 9.47183 | -0.0170162 | -0.00661674 | -0.180061 | -0.00882481 | 0.0204038 | 0.166694 |     -0.0204264 |     -0.0652289 |   3.94982 |   10.0915 |   6.03288 |   5.94702 |   4.05133 |\n",
      "Frame:2\n",
      "<PIL.Image.Image image mode=RGB size=1242x375 at 0x7F8AE9FE2610>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maksimekineren/Desktop/Maksim/UMBC/Classes/Spring 2021/CMSC 611/Project/pyCarDisplay/examples/model.py:504: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  ../aten/src/ATen/native/IndexingUtils.h:30.)\n",
      "  image_boxes.append(class_decoded_locs[1 - suppress])\n",
      "/Users/maksimekineren/Desktop/Maksim/UMBC/Classes/Spring 2021/CMSC 611/Project/pyCarDisplay/examples/model.py:506: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  ../aten/src/ATen/native/IndexingUtils.h:30.)\n",
      "  image_scores.append(class_scores[1 - suppress])\n",
      "/Users/maksimekineren/Desktop/Maksim/UMBC/Classes/Spring 2021/CMSC 611/Project/pyCarDisplay/examples/model.py:504: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  ../aten/src/ATen/native/IndexingUtils.h:30.)\n",
      "  image_boxes.append(class_decoded_locs[1 - suppress])\n",
      "/Users/maksimekineren/Desktop/Maksim/UMBC/Classes/Spring 2021/CMSC 611/Project/pyCarDisplay/examples/model.py:506: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  ../aten/src/ATen/native/IndexingUtils.h:30.)\n",
      "  image_scores.append(class_scores[1 - suppress])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 * 14\n",
      "x = 1091.9429931640625\n",
      "y = 207.96954345703125\n",
      "64 * 14\n",
      "x = 1107.5311279296875\n",
      "y = 166.41427612304688\n",
      "64 * 14\n",
      "x = 721.9058227539062\n",
      "y = 169.97549438476562\n",
      "{'annotated_image': <PIL.Image.Image image mode=RGB size=1242x375 at 0x7F8AE9FE2610>, 'box_info': {'text_size': [(64, 14), (64, 14), (64, 14)], 'box_location': [[1091.9429931640625, 207.96954345703125, 1238.714599609375, 320.8197326660156], [1107.5311279296875, 166.41427612304688, 1225.9854736328125, 300.9481506347656], [721.9058227539062, 169.97549438476562, 765.7407836914062, 238.7466278076172]]}, 'detected': True}\n",
      "Object detected:3\n",
      "|    |    lat |    lon |     alt |       roll |      pitch |      yaw |       vn |       ve |      vf |         vl |        vu |       ax |        ay |      az |       af |       al |      au |         wx |       wy |          wz |        wf |         wl |         wu |   pos_accuracy |   vel_accuracy |   navstat |   numsats |   posmode |   velmode |   orimode |\n",
      "|---:|-------:|-------:|--------:|-----------:|-----------:|---------:|---------:|---------:|--------:|-----------:|----------:|---------:|----------:|--------:|---------:|---------:|--------:|-----------:|---------:|------------:|----------:|-----------:|-----------:|---------------:|---------------:|----------:|----------:|----------:|----------:|----------:|\n",
      "|  0 | 49.024 | 8.5285 | 116.254 | -0.0565202 | -0.0297918 | -2.89221 | -4.41591 | -10.5331 | 11.4573 | -0.0563533 | -0.222162 | 0.234565 | -0.163049 | 9.76117 | 0.357936 | 0.141231 | 10.0273 | 0.00980303 | 0.016844 | -0.00632604 | -0.199518 | -0.0115363 | 0.00744502 |       0.277725 |     -0.0036156 |   4.03015 |   9.99653 |   5.88313 |   6.11428 | 0.0751933 |\n",
      "Frame:3\n",
      "<PIL.Image.Image image mode=RGB size=1242x375 at 0x7F8AF87F0760>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maksimekineren/Desktop/Maksim/UMBC/Classes/Spring 2021/CMSC 611/Project/pyCarDisplay/examples/model.py:504: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  ../aten/src/ATen/native/IndexingUtils.h:30.)\n",
      "  image_boxes.append(class_decoded_locs[1 - suppress])\n",
      "/Users/maksimekineren/Desktop/Maksim/UMBC/Classes/Spring 2021/CMSC 611/Project/pyCarDisplay/examples/model.py:506: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  ../aten/src/ATen/native/IndexingUtils.h:30.)\n",
      "  image_scores.append(class_scores[1 - suppress])\n",
      "/Users/maksimekineren/Desktop/Maksim/UMBC/Classes/Spring 2021/CMSC 611/Project/pyCarDisplay/examples/model.py:504: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  ../aten/src/ATen/native/IndexingUtils.h:30.)\n",
      "  image_boxes.append(class_decoded_locs[1 - suppress])\n",
      "/Users/maksimekineren/Desktop/Maksim/UMBC/Classes/Spring 2021/CMSC 611/Project/pyCarDisplay/examples/model.py:506: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  ../aten/src/ATen/native/IndexingUtils.h:30.)\n",
      "  image_scores.append(class_scores[1 - suppress])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 * 14\n",
      "x = 1093.9437255859375\n",
      "y = 207.99391174316406\n",
      "64 * 14\n",
      "x = 1111.2525634765625\n",
      "y = 166.06039428710938\n",
      "64 * 14\n",
      "x = 720.5986938476562\n",
      "y = 181.98043823242188\n",
      "{'annotated_image': <PIL.Image.Image image mode=RGB size=1242x375 at 0x7F8AF87F0760>, 'box_info': {'text_size': [(64, 14), (64, 14), (64, 14)], 'box_location': [[1093.9437255859375, 207.99391174316406, 1235.3162841796875, 322.8355407714844], [1111.2525634765625, 166.06039428710938, 1219.9837646484375, 303.6865539550781], [720.5986938476562, 181.98043823242188, 768.7105712890625, 246.66793823242188]]}, 'detected': True}\n",
      "Object detected:3\n",
      "|    |     lat |     lon |     alt |      roll |     pitch |      yaw |       vn |       ve |     vf |         vl |        vu |      ax |        ay |     az |       af |       al |      au |         wx |       wy |        wz |        wf |       wl |        wu |   pos_accuracy |   vel_accuracy |   navstat |   numsats |   posmode |   velmode |   orimode |\n",
      "|---:|--------:|--------:|--------:|----------:|----------:|---------:|---------:|---------:|-------:|-----------:|----------:|--------:|----------:|-------:|---------:|---------:|--------:|-----------:|---------:|----------:|----------:|---------:|----------:|---------------:|---------------:|----------:|----------:|----------:|----------:|----------:|\n",
      "|  0 | 49.0934 | 8.34051 | 116.443 | -0.164839 | 0.0708047 | -2.54242 | -4.65837 | -11.3523 | 12.191 | -0.0839308 | -0.138029 | 0.62705 | -0.293387 | 9.9773 | 0.613867 | 0.206019 | 9.84776 | -0.0433231 | 0.141658 | -0.134716 | 0.0115061 | 0.190721 | -0.173755 |      0.0475323 |      0.0394419 |   4.07818 |    8.8763 |   5.86795 |   6.05219 | 0.0296985 |\n",
      "Frame:4\n",
      "<PIL.Image.Image image mode=RGB size=1242x375 at 0x7F8AF8782A30>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maksimekineren/Desktop/Maksim/UMBC/Classes/Spring 2021/CMSC 611/Project/pyCarDisplay/examples/model.py:504: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  ../aten/src/ATen/native/IndexingUtils.h:30.)\n",
      "  image_boxes.append(class_decoded_locs[1 - suppress])\n",
      "/Users/maksimekineren/Desktop/Maksim/UMBC/Classes/Spring 2021/CMSC 611/Project/pyCarDisplay/examples/model.py:506: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  ../aten/src/ATen/native/IndexingUtils.h:30.)\n",
      "  image_scores.append(class_scores[1 - suppress])\n",
      "/Users/maksimekineren/Desktop/Maksim/UMBC/Classes/Spring 2021/CMSC 611/Project/pyCarDisplay/examples/model.py:504: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  ../aten/src/ATen/native/IndexingUtils.h:30.)\n",
      "  image_boxes.append(class_decoded_locs[1 - suppress])\n",
      "/Users/maksimekineren/Desktop/Maksim/UMBC/Classes/Spring 2021/CMSC 611/Project/pyCarDisplay/examples/model.py:506: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  ../aten/src/ATen/native/IndexingUtils.h:30.)\n",
      "  image_scores.append(class_scores[1 - suppress])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 * 14\n",
      "x = 893.6401977539062\n",
      "y = 204.55279541015625\n",
      "64 * 14\n",
      "x = 900.0587158203125\n",
      "y = 139.23362731933594\n",
      "{'annotated_image': <PIL.Image.Image image mode=RGB size=1242x375 at 0x7F8AF8782A30>, 'box_info': {'text_size': [(64, 14), (64, 14)], 'box_location': [[893.6401977539062, 204.55279541015625, 1001.4647216796875, 337.8184814453125], [900.0587158203125, 139.23362731933594, 997.7452392578125, 320.7552185058594]]}, 'detected': True}\n",
      "Object detected:2\n",
      "|    |     lat |     lon |     alt |        roll |     pitch |      yaw |       vn |       ve |      vf |       vl |        vu |       ax |        ay |      az |       af |         al |      au |       wx |         wy |         wz |        wf |         wl |        wu |   pos_accuracy |   vel_accuracy |   navstat |   numsats |   posmode |   velmode |   orimode |\n",
      "|---:|--------:|--------:|--------:|------------:|----------:|---------:|---------:|---------:|--------:|---------:|----------:|---------:|----------:|--------:|---------:|-----------:|--------:|---------:|-----------:|-----------:|----------:|-----------:|----------:|---------------:|---------------:|----------:|----------:|----------:|----------:|----------:|\n",
      "|  0 | 49.0394 | 8.46651 | 116.329 | -0.00395463 | 0.0426862 | -2.85472 | -3.55493 | -9.84444 | 10.4565 | 0.018492 | -0.182707 | 0.736387 | -0.200617 | 9.69548 | 0.881245 | -0.0186985 | 9.85558 | 0.171726 | -0.0185291 | -0.0544333 | -0.106633 | -0.0750254 | 0.0132975 |      0.0655158 |      0.0432896 |   4.08272 |   11.0013 |   6.14535 |   5.97353 |   4.27202 |\n",
      "Frame:5\n",
      "<PIL.Image.Image image mode=RGB size=1242x375 at 0x7F8B183DBC10>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maksimekineren/Desktop/Maksim/UMBC/Classes/Spring 2021/CMSC 611/Project/pyCarDisplay/examples/model.py:504: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  ../aten/src/ATen/native/IndexingUtils.h:30.)\n",
      "  image_boxes.append(class_decoded_locs[1 - suppress])\n",
      "/Users/maksimekineren/Desktop/Maksim/UMBC/Classes/Spring 2021/CMSC 611/Project/pyCarDisplay/examples/model.py:506: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  ../aten/src/ATen/native/IndexingUtils.h:30.)\n",
      "  image_scores.append(class_scores[1 - suppress])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45 * 14\n",
      "x = 14.82154369354248\n",
      "y = 124.7120132446289\n",
      "{'annotated_image': <PIL.Image.Image image mode=RGB size=1242x375 at 0x7F8B183DBC10>, 'box_info': {'text_size': [(45, 14)], 'box_location': [[14.82154369354248, 124.7120132446289, 294.25909423828125, 209.1750946044922]]}, 'detected': True}\n",
      "Object detected:1\n",
      "|    |     lat |     lon |     alt |      roll |      pitch |      yaw |       vn |       ve |      vf |       vl |        vu |       ax |       ay |      az |       af |       al |      au |          wx |         wy |      wz |        wf |        wl |       wu |   pos_accuracy |   vel_accuracy |   navstat |   numsats |   posmode |   velmode |   orimode |\n",
      "|---:|--------:|--------:|--------:|----------:|-----------:|---------:|---------:|---------:|--------:|---------:|----------:|---------:|---------:|--------:|---------:|---------:|--------:|------------:|-----------:|--------:|----------:|----------:|---------:|---------------:|---------------:|----------:|----------:|----------:|----------:|----------:|\n",
      "|  0 | 49.0769 | 8.34595 | 116.233 | 0.0283502 | -0.0118503 | -2.67521 | -4.33941 | -10.4764 | 11.2663 | -0.18009 | -0.102945 | 0.515194 | 0.204523 | 9.46218 | 0.546503 | 0.403191 | 9.48824 | -0.00211785 | 0.00753097 | -0.1027 | 0.0184077 | 0.0580052 | 0.120059 |       0.136781 |      -0.122146 |   3.90622 |   10.0515 |   6.05138 |    6.0515 |  0.385273 |\n",
      "Frame:6\n",
      "<PIL.Image.Image image mode=RGB size=1242x375 at 0x7F8AE9FE2610>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maksimekineren/Desktop/Maksim/UMBC/Classes/Spring 2021/CMSC 611/Project/pyCarDisplay/examples/model.py:504: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  ../aten/src/ATen/native/IndexingUtils.h:30.)\n",
      "  image_boxes.append(class_decoded_locs[1 - suppress])\n",
      "/Users/maksimekineren/Desktop/Maksim/UMBC/Classes/Spring 2021/CMSC 611/Project/pyCarDisplay/examples/model.py:506: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  ../aten/src/ATen/native/IndexingUtils.h:30.)\n",
      "  image_scores.append(class_scores[1 - suppress])\n",
      "/Users/maksimekineren/Desktop/Maksim/UMBC/Classes/Spring 2021/CMSC 611/Project/pyCarDisplay/examples/model.py:504: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  ../aten/src/ATen/native/IndexingUtils.h:30.)\n",
      "  image_boxes.append(class_decoded_locs[1 - suppress])\n",
      "/Users/maksimekineren/Desktop/Maksim/UMBC/Classes/Spring 2021/CMSC 611/Project/pyCarDisplay/examples/model.py:506: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  ../aten/src/ATen/native/IndexingUtils.h:30.)\n",
      "  image_scores.append(class_scores[1 - suppress])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 * 14\n",
      "x = 977.7435302734375\n",
      "y = 258.00177001953125\n",
      "64 * 14\n",
      "x = 962.8386840820312\n",
      "y = 132.92919921875\n",
      "{'annotated_image': <PIL.Image.Image image mode=RGB size=1242x375 at 0x7F8AE9FE2610>, 'box_info': {'text_size': [(64, 14), (64, 14)], 'box_location': [[977.7435302734375, 258.00177001953125, 1143.631103515625, 376.2857666015625], [962.8386840820312, 132.92919921875, 1089.467041015625, 354.8659973144531]]}, 'detected': True}\n",
      "Object detected:2\n",
      "|    |     lat |     lon |     alt |      roll |      pitch |      yaw |       vn |       ve |      vf |         vl |       vu |       ax |       ay |     az |       af |      al |      au |       wx |         wy |        wz |         wf |        wl |        wu |   pos_accuracy |   vel_accuracy |   navstat |   numsats |   posmode |   velmode |   orimode |\n",
      "|---:|--------:|--------:|--------:|----------:|-----------:|---------:|---------:|---------:|--------:|-----------:|---------:|---------:|---------:|-------:|---------:|--------:|--------:|---------:|-----------:|----------:|-----------:|----------:|----------:|---------------:|---------------:|----------:|----------:|----------:|----------:|----------:|\n",
      "|  0 | 49.0714 | 8.54523 | 116.442 | 0.0468321 | -0.0218139 | -2.67188 | -4.41219 | -10.4616 | 11.2537 | -0.0028291 | 0.192797 | 0.227928 | 0.210802 | 9.5411 | 0.460268 | 0.42545 | 9.70033 | -0.11408 | -0.0694797 | 0.0883179 | -0.0791476 | 0.0240626 | 0.0249389 |     -0.0337594 |       0.230015 |   4.06339 |   9.79749 |   6.01865 |   5.93382 | 0.0852433 |\n",
      "Frame:7\n",
      "<PIL.Image.Image image mode=RGB size=1242x375 at 0x7F8AF87F0A00>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-72d58caef480>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/pycardisplay/lib/python3.8/site-packages/pyCarDisplay-0.0.0-py3.8.egg/pyCarDisplay/pyCarDisplay.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self, **parameters)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# TODO: Perform any parameter/path checks here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/pycardisplay/lib/python3.8/site-packages/pyCarDisplay-0.0.0-py3.8.egg/pyCarDisplay/car.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0;31m# return data: {\"annotated_image\": PIL.Image,\"box_info\":{\"text_size\":list(),\"box_location\":list()} }\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m             \u001b[0mdetected_dictionary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj_detection_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetected_dictionary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/pycardisplay/lib/python3.8/site-packages/pyCarDisplay-0.0.0-py3.8.egg/pyCarDisplay/detection/object_detection_api.py\u001b[0m in \u001b[0;36mdetect\u001b[0;34m(self, original_image, suppress, min_score, max_overlap, top_k)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \"\"\"\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__detect_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_overlap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_overlap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtop_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuppress\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msuppress\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# .show()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/pycardisplay/lib/python3.8/site-packages/pyCarDisplay-0.0.0-py3.8.egg/pyCarDisplay/detection/object_detection_api.py\u001b[0m in \u001b[0;36m__detect_helper\u001b[0;34m(self, original_image, min_score, max_overlap, top_k, suppress)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;31m# Forward prop.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mpredicted_locs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m# Detect objects in SSD output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/pycardisplay/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Maksim/UMBC/Classes/Spring 2021/CMSC 611/Project/pyCarDisplay/examples/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0;31m# Run prediction convolutions (predict offsets w.r.t prior-boxes and classes in each resulting localization box)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m         locs, classes_scores = self.pred_convs(conv4_3_feats, conv7_feats, conv8_2_feats, conv9_2_feats, conv10_2_feats,\n\u001b[0m\u001b[1;32m    370\u001b[0m                                                conv11_2_feats)  # (N, 8732, 4), (N, 8732, n_classes)\n\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/pycardisplay/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Maksim/UMBC/Classes/Spring 2021/CMSC 611/Project/pyCarDisplay/examples/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, conv4_3_feats, conv7_feats, conv8_2_feats, conv9_2_feats, conv10_2_feats, conv11_2_feats)\u001b[0m\n\u001b[1;32m    294\u001b[0m                                    self.n_classes)  # (N, 5776, n_classes), there are a total 5776 boxes on this feature map\n\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m         \u001b[0mc_conv7\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcl_conv7\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv7_feats\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (N, 6 * n_classes, 19, 19)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m         \u001b[0mc_conv7\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_conv7\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (N, 19, 19, 6 * n_classes)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         c_conv7 = c_conv7.view(batch_size, -1,\n",
      "\u001b[0;32m/opt/anaconda3/envs/pycardisplay/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/pycardisplay/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/pycardisplay/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    393\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 395\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    396\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "display.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
